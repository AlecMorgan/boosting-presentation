\section{You Could Have Invented Gradient Boosting}
%
\begin{frame}
Let's start with our basic setup.\\~\\

$\{ x_i, y_i \}$ is a data set, where $i$ indexes the samples we have available for training our model.\\~\\

Each $x_i$ may be a vector, in which case I'll refer to it's components (if needed) as $x_{ij}$.
\end{frame}
%
\begin{frame}
Our goal is to construct a function $f$ so that, approximately

$$ y_i \approx f(x_i) \ \text{for all} \ i $$

\end{frame}
%
\begin{frame}
\textbf{Question:} What should the domain of $f$ be?
\end{frame}
%
\begin{frame}
\textbf{Degenerate Choice:} $\text{Domain}(f) = \{x_i\}$.\\~\\

That is, let's only attempt to define $f$ on our training sample.
\end{frame}
%
\begin{frame}
\begin{center}
"But Matt.  This is silly.  The answer is obvious."
\end{center}

$$ \textbf{Define:} \ f(x_i) = y_i $$
\end{frame}
%
\begin{frame}
\textbf{True}.\\~\\

But let's try to derive this in a creative way.
\end{frame}
%
\begin{frame}
\textbf{Recall}: Gradient descent is a general purpose algorithm for optimizing any objective function $L(x)$.

\textbf{Algorithm:} Gradient Descent to Minimize a function $L$.

\begin{itemize}
  \item Compute $\nabla L(x)$ somehow, on paper is good.
  \item Initialize $x_0 = 0$ (for example, there may be more principled choices).
  \item Until satisfied, iterate: \begin{itemize}
    \item Set $x_{i+1} = x_i - \nabla L(x_i)$.
  \end{itemize}
\end{itemize}

\end{frame}
%
\begin{frame}
Let's focus on a single point in our domain, and stick with the classic squared error loss function

$$ L(f, y) = \frac{1}{2} (y - f)^2 $$

Here $f$ is not a function yet, it is just a number.
\end{frame}
%
\begin{frame}
Following the gradient descent recipe for optimizing this loss function, let's initialize $f$ to the average value of $y_i$

$$ f_0 = \frac{1}{N} \sum_i y_i $$
\end{frame}
%
\begin{frame}
And compute the gradient with respect to $f$ by hand

$$ \nabla_{f} (f, y) = \frac{\partial}{\partial f} \frac{1}{2} (y - f)^2 = f - y $$
\end{frame}
%
\begin{frame}
...and apply the update rule

$$ f_1 = f_0 - \nabla_{f} (f_0, y) = f_0 - (f_0 - y) = y $$

So this (admittedly quite bizarre) application of gradient descent immediately recovers the correct solution

$$ f(x_i) = y_i $$

for every data point.
\end{frame}
%
\begin{frame}
\begin{center}
 What is stopping up from applying this scheme in the more realistic situation where we want to construct a function $f$ with domain $\mathbb{R}^n$ so that
\end{center}

$$ f(x_i) \approx y_i $$
\end{frame}
%
\begin{frame}
The \textbf{first step works}, we can certainly define $f_0$ to be the constant function

$$ f(x) = \frac{1}{N} \sum_i y_i \ \text{for all} \ x \in \mathbb{R}^n $$
\end{frame}
%
\begin{frame}
The \textbf{update step fails}, we cannot evaluate the gradient at any point where we have not observed a value of $y$.

$$ \nabla_f (f, y) = f - y $$
\end{frame}
%
\begin{frame}
\textbf{Solution:} Fit a simple model to the new dataset

$$ \{x_i, \nabla_f L(f_0(x_i), y_i) \} = \{x_i, f_0(x_i) - y_i \} $$

The \textbf{predictions from this model} can be viewed as an extension of the gradient to all of $\mathbb{R}^n$.
\end{frame}
%
\begin{frame}
\textbf{Algorithm:} Gradient Boosting to Minimize Sum of Squared Errors.\\~\\

\textbf{Inputs:} A data set $\{ x_i, y_i \}$.

\textbf{Returns:} A function $f$ such that $f(x_i) \approx y_i$.

\begin{itemize}
  \item Initialize $f_0(x) = \frac{1}{N} \sum_i y_i$.
  \item Iterate (parameter $k$) until satisfied: \begin{itemize}
    \item Create the working data set $W_k = \{ x_i, f_k(x_i) - y_i \}$.
    \item Fit a decision tree to $W_k$, minimizing least squares (though most anything would work here).  Call this tree $T_k$.
    \item Set $f_{k+1}(x) = f_{k}(x) - T_{k}(x)$. 
  \end{itemize}
  \item Return $f_{\text{max}}(x) = f_0(x) - T_1(x) - T_2(X) - \cdots - T_{\text{max}}(x)$.
\end{itemize}
\end{frame}
%
\begin{frame}
\textbf{Comments:}

\begin{itemize}
  \item We didn't \textit{have} to use decision trees, literally anything would work.
  \item Just like in other algorithms, we can introduce a \textit{learning rate} to make the gradient descent more robust
  $$ x_{i+1} = x_i - \lambda \nabla L(x_i) $$
This is particularly important in boosting, to prevent overfitting.
  \item We could have fit the tree to the negative gradient, which would have resulted in the more aesthetically appealing
  $$ f_{\text{max}}(x) = f_0(x) + T_1(x) + T_2(X) + \cdots + T_{\text{max}}(x) $$
\end{itemize}

\end{frame}




